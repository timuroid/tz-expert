"""
llm.py -> llm_service.py
-------
–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ Chat Completion API.
–†–∞–±–æ—Ç–∞–µ—Ç ¬´–∏–∑ –∫–æ—Ä–æ–±–∫–∏¬ª —Å OpenAI ( https://api.openai.com/v1 ),
–Ω–æ –±–∞–∑–æ–≤—ã–π URL –∏ –∏–º—è –º–æ–¥–µ–ª–∏ –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è –∏–∑ settings ‚Äï –∏—Ö –ª–µ–≥–∫–æ
–∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —ç–Ω–¥-–ø–æ–π–Ω—Ç/–º–æ–¥–µ–ª—å –±–µ–∑ –ø—Ä–∞–≤–∫–∏ –∫–æ–¥–∞.
"""
import re, json,  httpx
from pathlib import Path
from typing import List, Tuple
from openai import AsyncOpenAI         # –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç ‚â• 1.0
from tz_expert.settings import settings            # —Å–º. –Ω–∏–∂–µ
import asyncio
_YC_CONCURRENCY = asyncio.Semaphore(10)   # —Å—Ç–æ–ª—å–∫–æ –Ω–∞–º —Ä–∞–∑—Ä–µ—à–µ–Ω–æ


JSON_RE = re.compile(r"```(?:json)?\s*(\{.*?\})\s*```", re.S)  # –Ω–æ–≤–∞—è - –∏—â–µ—Ç JSON –≤ markdown-–±–ª–æ–∫–∞—Ö
JSON_SIMPLE_RE = re.compile(r"\{.*\}", re.S)  # –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø—Ä–æ—Å—Ç–æ JSON –±–µ–∑ –±–ª–æ–∫–æ–≤

class LLMError(RuntimeError):
    """–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ–±—â–µ–Ω–∏–∏ —Å LLM."""


# ‚îÄ‚îÄ –ó–∞–≥—Ä—É–∂–∞–µ–º system-prompt-—ã –∏ —Å—Ö–µ–º—ã 
PROMPT_DIR = Path(__file__).resolve().parents[2] / "prompts"

TRIAGE_SYSTEM = (PROMPT_DIR / "triage.system.txt").read_text(encoding="utf-8")
TRIAGE_GROUP_SYSTEM = (PROMPT_DIR / "triage_group.system.txt").read_text(encoding="utf-8")
DEEP_SYSTEM   = (PROMPT_DIR / "deep.system.txt").read_text(encoding="utf-8")

# ------------------------------------------------------------------
#    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –Ω–∞ –≤—Å—ë –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
#    (–æ–Ω –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–µ–Ω –∏ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ—Ç HTTP-–∫–æ–Ω–Ω–µ–∫—Ç—ã)
# ------------------------------------------------------------------
# ‚îÄ‚îÄ‚îÄ OpenRouter –∫–ª–∏–µ–Ω—Ç (OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
or_client = AsyncOpenAI(
    api_key=settings.or_api_key,
    base_url=settings.or_base_url,   # "https://openrouter.ai/api/v1"
    default_headers={
        "HTTP-Referer": settings.or_referer,
        "X-Title":      settings.or_title,
    },
    timeout=60,
)

# ‚îÄ‚îÄ‚îÄ Yandex GPT —Å—ã—Ä–æ–π HTTP client ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
yc_client = httpx.AsyncClient(
    base_url="https://llm.api.cloud.yandex.net",
    headers={"Authorization": f"Api-Key {settings.yc_api_key}"},
    timeout=60,
)

# ---------- helpers -------------------------------------------------------


# ------------------------------------------------------------------
#    –§—É–Ω–∫—Ü–∏—è-–æ–±—ë—Ä—Ç–∫–∞: –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å–æ–≤–º–µ—Å—Ç–∏–º —Å–æ —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–µ–π
# ------------------------------------------------------------------
def _extract_json(raw: str) -> dict:
    raw = raw.strip()

    # ---------- –∏—â–µ–º JSON-—Ç–µ–ª–æ ----------
    if raw.startswith("{"):
        json_text = raw
    else:
        m = JSON_RE.search(raw) or JSON_SIMPLE_RE.search(raw)
        if not m:
            raise LLMError(f"No JSON found in LLM answer:\n{raw[:300]}")
        json_text = m.group(1) if m.re is JSON_RE else m.group(0)

    # ---------- –≤—ã—Ä–µ–∑–∞–µ–º \x00‚Äì\x1F, \x7F ----------
    json_text = re.sub(r"[\x00-\x1f\x7f]", "", json_text)

    try:
        return json.loads(json_text)
    except json.JSONDecodeError as e:
        raise LLMError(f"Invalid JSON from LLM: {e}") from e



async def _call_openrouter(
    messages: List[dict],
    model: str,
    json_schema: dict,           # üö© –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û!
):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç json-schema —á–µ—Ä–µ–∑ OpenRouter Structured Output.

    json_schema –æ–∂–∏–¥–∞–µ—Ç—Å—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
    {
        "name":   "<–ª—é–±–æ–µ-–∏–º—è>",
        "schema": {... pydantic-schema ...}
    }
    """
    payload = {
        "model": model,
        "messages": messages,
        "temperature": 0,
        "response_format": {           # <<< –≥–ª–∞–≤–Ω–æ–µ –æ—Ç–ª–∏—á–∏–µ
            "type": "json_schema",
            "json_schema": {
                "name":   json_schema["name"],
                "strict": True,
                "schema": json_schema["schema"],
            },
        },
    }

    resp = await or_client.chat.completions.create(**payload)
    content = resp.choices[0].message.content
    obj     = _extract_json(content)
    usage   = resp.usage.model_dump()

    return obj, usage


def _oa_to_yc(messages: List[dict]) -> list[dict]:
    """OpenAI-—Ñ–æ—Ä–º–∞—Ç ‚Üí —Ñ–æ—Ä–º–∞—Ç Yandex GPT"""
    return [{"role": m["role"], "text": m["content"]} for m in messages]


async def _call_yandex(
    messages: List[dict],
    model_uri: str,
    json_schema: dict,           # üö© –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û!
):
    """
    Yandex GPT ‚â• v2: json_schema –∏–¥—ë—Ç –≤–µ—Ä—Ö–Ω–∏–º –ø–æ–ª–µ–º –∑–∞–ø—Ä–æ—Å–∞.
    """
    payload = {
        "modelUri": model_uri,
        "messages": _oa_to_yc(messages),
        "json_schema": {          # <<< –≥–ª–∞–≤–Ω–æ–µ –æ—Ç–ª–∏—á–∏–µ
            "schema": json_schema["schema"]
        },
    }

    async with _YC_CONCURRENCY:
        r = await yc_client.post("/foundationModels/v1/completion", json=payload)

    if r.status_code == 429:
        raise RuntimeError("Yandex quota: 429 Too Many Requests")
    if r.status_code != 200:
        raise RuntimeError(f"YC {r.status_code}: {r.text[:200]}")

    data  = r.json()
    text  = data["result"]["alternatives"][0]["message"]["text"]
    obj   = _extract_json(text)
    usage = {
        "prompt_tokens":     int(data["result"]["usage"].get("inputTextTokens", 0)),
        "completion_tokens": int(data["result"]["usage"].get("completionTokens", 0)),
        "total_tokens":      int(data["result"]["usage"].get("totalTokens", 0)),
    }
    return obj, usage


# -----------------------------------------------------------------
#  retry-wrapper: –¥–æ 2 –ø–æ–≤—Ç–æ—Ä–æ–≤, –µ—Å–ª–∏ _extract_json –±—Ä–æ—Å–∏–ª LLMError
# -----------------------------------------------------------------
async def _call_with_retry(caller, *args, max_retry: int = 2):
    """
    caller  ‚Äì —Ñ—É–Ω–∫—Ü–∏—è _call_openrouter –∏–ª–∏ _call_yandex
    args[0] ‚Äì messages (list[dict]); –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–µ –¥–æ–±–∞–≤–ª—è–µ–º fix-prompt
    """
    messages = list(args[0])
    others   = args[1:]

    for attempt in range(max_retry + 1):
        try:
            return await caller(messages, *others)
        except LLMError as e:
            if "Invalid JSON" not in str(e):
                raise                         # –¥—Ä—É–≥–∞—è –ø—Ä–∏—á–∏–Ω–∞ ‚Äì –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º
            if attempt == max_retry:
                raise                         # –∏—Å—á–µ—Ä–ø–∞–Ω—ã –ø–æ–ø—ã—Ç–∫–∏
            messages = messages + [{
                "role": "user",
                "content": (
                    "‚ùó –§–æ—Ä–º–∞—Ç –Ω–∞—Ä—É—à–µ–Ω. –í–µ—Ä–Ω–∏ –†–û–í–ù–û –≤–∞–ª–∏–¥–Ω—ã–π JSON-–æ–±—ä–µ–∫—Ç."
                ),
            }]

# ‚îÄ‚îÄ‚îÄ –ø—É–±–ª–∏—á–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def ask_llm(
        messages: List[dict],
        json_schema: dict,
        model: str | None = None
) -> Tuple[dict, dict]:
    """
    ‚Ä¢ model == None  ‚Üí  –¥–µ—Ñ–æ–ª—Ç Qwen-3-235B —á–µ—Ä–µ–∑ OpenRouter
    ‚Ä¢ model.startswith("openrouter/")   ‚Üí  –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å –≤ OpenRouter
    ‚Ä¢ model.startswith("gpt://")        ‚Üí  –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å –≤ Yandex Cloud
    ‚Ä¢ –∏–Ω–∞—á–µ                              ‚Üí  —Å—á–∏—Ç–∞–µ–º —Å—Ç—Ä–æ–∫–æ–π-—à–æ—Ä—Ç–∫–∞—Ç–æ–º Yandex-–º–æ–¥–µ–ª–∏
                                           –∏ –ø—Ä–æ—Å—Ç–æ –ø—Ä–∏–∫–ª–µ–∏–≤–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å
                                           gpt://<FOLDER>/ + <model>
    """
    # ---- 0. –î–µ—Ñ–æ–ª—Ç: Qwen 235B (OpenRouter) -------------------
    if not model:
        return await _call_with_retry(_call_openrouter, messages,"qwen/qwen3-235b-a22b-2507", json_schema)

    # ---- 1. –ü–æ–ª–Ω—ã–π –º–∞—Ä—à—Ä—É—Ç OpenRouter ------------------------
    if model.startswith("openrouter/"):
        return await _call_with_retry(_call_openrouter, messages, model, json_schema)

    # ---- 2. –ü–æ–ª–Ω—ã–π URI Yandex Cloud --------------------------
    if model.startswith("gpt://"):
        return await _call_with_retry(_call_yandex, messages, model, json_schema)


    # ---- 3. –ö–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è Yandex ‚Üí –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å ----------
    yc_uri = f"gpt://{settings.yc_folder_id}/{model}"
    return await _call_with_retry(_call_yandex, messages, yc_uri, json_schema)

